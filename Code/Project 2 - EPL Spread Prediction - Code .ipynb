{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scrape Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "chromedriver = \"/Applications/chromedriver\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "\n",
    "EPL_scrape = pd.DataFrame(columns=['home_possession', 'away_possession', 'home_passes', 'away_passes', 'home_offsides', 'away_offsides', 'attendance'])\n",
    "\n",
    "\n",
    "# for loop to run through all games of 17/18 season 22342-22721 - 380 games\n",
    "def scrape_possession_and_passes(dataframe):\n",
    "\n",
    "    \n",
    "    for num in range(22342, 22722):\n",
    "        partial_url = 'https://www.premierleague.com/match/'\n",
    "        url = partial_url + str(num)    \n",
    "        driver.get(url)\n",
    "        \n",
    "        # let the page load correctly\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # click the stats tab\n",
    "        \n",
    "        try:\n",
    "            elem1 = driver.find_element_by_xpath('//*[@id=\"mainContent\"]/div/section/div[2]/div[2]/div[1]/div/div/ul/li[3]')\n",
    "            elem1.click()\n",
    "        except NoSuchElementException:  \n",
    "            pass\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            elem2 = driver.find_element_by_xpath('//*[@id=\"mainContent\"]/div/section/div[2]/div/div[1]/div/div/ul/li[3]')\n",
    "            elem2.click()\n",
    "        except NoSuchElementException:  \n",
    "            pass     \n",
    "        \n",
    "        \n",
    "        \n",
    "        try:\n",
    "            elem3 = driver.find_element_by_xpath('//*[@id=\"mainContent\"]/div/section/div[2]/div/div[1]/div/div/ul/li[3]')\n",
    "            elem3.click()\n",
    "        except NoSuchElementException as e: print(e, num)\n",
    "            \n",
    "            \n",
    "        \n",
    "            \n",
    "        time.sleep(2)\n",
    "        # things to scrape\n",
    "        element = driver.find_element_by_xpath('//*[@id=\"mainContent\"]/div/section/div[2]/div/div[2]/section[3]/div[2]/div[2]/table/tbody')\n",
    "        full_table = element.find_elements_by_tag_name('p')\n",
    "        \n",
    "        home_possession = full_table[0].text\n",
    "        away_possession = full_table[2].text\n",
    "        \n",
    "        home_passes = full_table[12].text\n",
    "        away_passes = full_table[14].text\n",
    "        \n",
    "        home_offsides = full_table[24].text\n",
    "        away_offsides = full_table[26].text\n",
    "        \n",
    "        crowd = driver.find_element_by_xpath('//*[@id=\"mainContent\"]/div/section/div[2]/section/div[3]/div/div/div[2]/div[2]').text\n",
    "        \n",
    "        attendance = crowd[7:]\n",
    "        \n",
    "        \n",
    "        \n",
    "        #append each page results to dataframe\n",
    "        dataframe = dataframe.append({'home_possession': str(home_possession), 'away_possession': str(away_possession), 'home_passes': str(home_passes), 'away_passes': str(away_passes), 'home_offsides': str(home_offsides), 'away_offsides': str(away_offsides), 'attendance': str(attendance)}, ignore_index=True)\n",
    "        \n",
    "        time.sleep(1)\n",
    "        #print(url)\n",
    "        #print(EPL_scrape.head())\n",
    "    dataframe.to_csv('EPL_scrape_1718_test1.csv')\n",
    "    return dataframe.shape\n",
    "\n",
    "scrape_possession_and_passes(EPL_scrape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Feature Engineering and Adding Web Scrape data to existing dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns and change data set name to results\n",
    "\n",
    "cols = ['Date', 'MatchDay', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'HST', 'AST', 'Home_total_goals_for', 'Home_total_goals_conceded', 'Away_total_goals_for', 'Away_total_goals_conceded', 'home_goal_diff', 'away_goal_diff','HomeTeam_rank', 'AwayTeam_rank', 'Home_Attack', 'Away_Attack', 'Home_D', 'Away_D']\n",
    "\n",
    "results = season_1718\n",
    "results = results.reindex(columns=list(cols))\n",
    "\n",
    "# add matchday values to data frame\n",
    "for week in range(0,380):\n",
    "    low = week*10\n",
    "    high = low + 10\n",
    "    match = week + 1\n",
    "    \n",
    "    for row in range(low, high):\n",
    "        results.MatchDay.loc[row] = match\n",
    "        \n",
    "# give all teams rank of 1 to start the season\n",
    "r = range(0, 10)\n",
    "results.HomeTeam_rank.iloc[r] = int(1)\n",
    "results.AwayTeam_rank.iloc[r] = int(1)\n",
    "\n",
    "# add quick calculation of goal difference columns per game to allow rest of code to work for ranking\n",
    "results.apply(lambda row: row.FTHG - row.FTAG, axis=1)\n",
    "results['home_goal_diff'] = results.apply(lambda row: row.FTHG - row.FTAG, axis=1)\n",
    "\n",
    "results.apply(lambda row: row.FTAG - row.FTHG, axis=1)\n",
    "results['away_goal_diff'] = results.apply(lambda row: row.FTAG - row.FTHG, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teams equal season.HomeTeam.unique\n",
    "teams = ['Arsenal', 'Brighton', 'Chelsea', 'Crystal Palace', 'Everton', 'Southampton', 'Watford', 'West Brom', 'Man United', 'Newcastle', 'Bournemouth', 'Burnley', 'Leicester', 'Liverpool', 'Stoke', 'Swansea', 'Huddersfield', 'Tottenham', 'Man City', 'West Ham']\n",
    "    \n",
    "# create a dictionary to track table pts for team rank value\n",
    "table_points = {}\n",
    "for team in teams:\n",
    "    if not team in table_points:\n",
    "        table_points[team] = 0\n",
    "    else:\n",
    "        table_points[team] += 1\n",
    "    \n",
    "# create a dictionary for running goal difference to use as tiebreaker when table points are equal\n",
    "running_goal_diff = {}\n",
    "for team in teams:\n",
    "    if not team in running_goal_diff:\n",
    "        running_goal_diff[team] = 0\n",
    "    else:\n",
    "        running_goal_diff[team] += 1\n",
    "            \n",
    "            \n",
    "# create a dictionary to track total goals for and total goals conceded for attack rank value\n",
    "total_goals_for = {}\n",
    "for team in teams:\n",
    "    if not team in total_goals_for:\n",
    "        total_goals_for[team] = 0\n",
    "    else:\n",
    "        total_goals_for[team] = 0\n",
    "            \n",
    "\n",
    "total_goals_conceded = {}\n",
    "for team in teams:\n",
    "    if not team in total_goals_conceded:\n",
    "        total_goals_conceded[team] = 0\n",
    "    else:\n",
    "        total_goals_conceded[team] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from collections import defaultdict\n",
    "\n",
    "for week in range(0, 39):\n",
    "    low = week*10\n",
    "    high = low + 10\n",
    "    match = week + 1\n",
    "    \n",
    "    \n",
    "    # update the league table by range of 10 games for each week - Table Points dictionary update\n",
    "    for row in range(low, high):\n",
    "        if results.FTR.iloc[row] == 'H':\n",
    "            table_points[str(results.HomeTeam.iloc[row])] += 3\n",
    "            table_points[str(results.AwayTeam.iloc[row])] += 0\n",
    "        \n",
    "        elif results.FTR.iloc[row] == 'A':\n",
    "            table_points[str(results.AwayTeam.iloc[row])] += 3\n",
    "            table_points[str(results.HomeTeam.iloc[row])] += 0\n",
    "\n",
    "        elif results.FTR.iloc[row] == 'D':\n",
    "            table_points[str(results.HomeTeam.iloc[row])] += 1\n",
    "            table_points[str(results.AwayTeam.iloc[row])] += 1\n",
    "        \n",
    "        else:\n",
    "            print('error in row', row)\n",
    "            \n",
    "    # update the goal differential in a new dictionary running_goal_diff\n",
    "    for row in range(low,high):\n",
    "        running_goal_diff[str(results.HomeTeam.iloc[row])] += results.home_goal_diff.iloc[row]\n",
    "        running_goal_diff[str(results.AwayTeam.iloc[row])] += results.away_goal_diff.iloc[row]\n",
    "    \n",
    "\n",
    "    # combine the sorted dictionaries for one list of teams ranked by pts and goal diff\n",
    "    weekly_pts = sorted(table_points.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    weekly_goal_diff = sorted(running_goal_diff.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "    \n",
    "    dd = defaultdict(list)\n",
    "\n",
    "    for d in (table_points, running_goal_diff): \n",
    "        for key, value in d.items():\n",
    "            dd[key].append(value)\n",
    "    \n",
    "    weekly_pts_goaldiff = sorted(dd.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "\n",
    "    for row in range(low, high):\n",
    "        home_team = results.HomeTeam.iloc[row]\n",
    "        index_list = [x for x, y in enumerate(weekly_pts_goaldiff) if y[0] == home_team]\n",
    "        results.HomeTeam_rank.iloc[row] = index_list[0] + 1\n",
    "    \n",
    "        away_team = results.AwayTeam.iloc[row]\n",
    "        index_list = [x for x, y in enumerate(weekly_pts_goaldiff) if y[0] == away_team]\n",
    "        results.AwayTeam_rank.iloc[row] = index_list[0] + 1\n",
    "    \n",
    "    for row in range(low, high):\n",
    "    \n",
    "        home_scored = results.FTHG.iloc[row]\n",
    "        away_scored = results.FTAG.iloc[row]\n",
    "    \n",
    "        total_goals_for[str(results.HomeTeam.iloc[row])] += home_scored\n",
    "        total_goals_for[str(results.AwayTeam.iloc[row])] += away_scored\n",
    "\n",
    "        total_goals_conceded[str(results.HomeTeam.iloc[row])] += away_scored\n",
    "        total_goals_conceded[str(results.AwayTeam.iloc[row])] += home_scored\n",
    "    \n",
    "    total_goals = defaultdict(list)\n",
    "\n",
    "    for d in (total_goals_for, total_goals_conceded): \n",
    "        for key, value in d.items():\n",
    "                total_goals[key].append(value)\n",
    "\n",
    "    for row in range(low, high):\n",
    "        home_team = results.HomeTeam.iloc[row]\n",
    "        #index_list = [x for x, y in enumerate(total_goals) if y[0] == home_team]\n",
    "        results.Home_total_goals_for.iloc[row] = total_goals[home_team][0]\n",
    "        results.Home_total_goals_conceded.iloc[row] = total_goals[home_team][1]\n",
    "        \n",
    "        away_team = results.AwayTeam.iloc[row]\n",
    "        #index_list = [x for x, y in enumerate(week1_pts_goaldiff) if y[0] == away_team]\n",
    "        results.Away_total_goals_for.iloc[row] = total_goals[away_team][0]\n",
    "        results.Away_total_goals_conceded.iloc[row] = total_goals[away_team][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add spread for each game\n",
    "results.apply(lambda row: row.FTHG - row.FTAG, axis=1)\n",
    "results['Spread'] = results.apply(lambda row: row.FTHG - row.FTAG, axis=1)\n",
    "\n",
    "# home attack and away attack code\n",
    "\n",
    "home_goal_agg_mean = 1.5403508771929826\n",
    "away_goal_agg_mean = 1.1859649122807017\n",
    "\n",
    "home_conceded_agg_mean = away_goal_agg_mean\n",
    "away_conceded_agg_mean = home_goal_agg_mean\n",
    "\n",
    "\n",
    "for row in range(0, 380):\n",
    "    results.Home_Attack[row] = ((results.Home_total_goals_for[row] / results.MatchDay[row]) / home_goal_agg_mean)\n",
    "    results.Away_Attack[row] = ((results.Away_total_goals_for[row] / results.MatchDay[row]) / away_goal_agg_mean)\n",
    "    \n",
    "    results.Home_D[row] = ((results.Home_total_goals_conceded[row] / results.MatchDay[row]) / home_conceded_agg_mean)\n",
    "    results.Away_D[row] = ((results.Away_total_goals_conceded[row] / results.MatchDay[row]) / away_conceded_agg_mean)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "#% config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, RidgeCV\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('1516_1617_1718.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = data.loc[:,['A_Promotion', 'HST', 'AST', 'H_vs_A_goal_diff_season', 'H_Fifa_ranked',\n",
    "    'Home_Attack', 'Away_Attack', 'Home_D', 'Away_D', 'H_A_Wage_Diff', 'Spread']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = small_data.loc[:,['A_Promotion', 'HST', 'AST', 'H_vs_A_goal_diff_season', 'H_Fifa_ranked',\n",
    "    'Home_Attack', 'Away_Attack', 'Home_D', 'Away_D', 'H_A_Wage_Diff']]\n",
    "\n",
    "y = small_data['Spread']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS    .50 R^2 on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = patsy.dmatrices('Spread ~ H_Promotion + A_Promotion + HST + AST + H_vs_A_goal_diff_season + H_Fifa_ranked + A_Fifa_ranked + HomeTeam_rank + AwayTeam_rank + Rank_ratio + Home_Attack + Away_Attack + Home_D + Away_D', data=smaller_data, return_type=\"dataframe\")\n",
    "\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "fit = model.fit()\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso and Ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['A_Promotion', 'HST', 'AST', 'H_vs_A_goal_diff_season', 'H_Fifa_ranked', 'Home_Attack', 'Away_Attack', 'Home_D', 'Away_D', 'H_A_Wage_Diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data 60 - 20 - 20 train/val/test\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2,random_state=19)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=.25, random_state=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the scaler\n",
    "std = StandardScaler()\n",
    "std.fit(X_train_val.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform with scaler\n",
    "X_tr = std.transform(X_train_val.values)\n",
    "X_te = std.transform(X_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso w 10 features + scaler transform   R^2 .523   RMSE 1.324"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoCV(alphas=array([1.00000e-02, 1.04737e-02, ..., 9.54772e+01, 1.00000e+02]),\n",
       "    copy_X=True, cv=5, eps=0.001, fit_intercept=True, max_iter=1000,\n",
       "    n_alphas=100, n_jobs=1, normalize=False, positive=False,\n",
       "    precompute='auto', random_state=None, selection='cyclic', tol=0.0001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphavec = 10**np.linspace(-2,2,200)\n",
    "\n",
    "lasso = LassoCV(alphas = alphavec, cv=5)\n",
    "lasso.fit(X_tr, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015885651294280528"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_pred = lasso.predict(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4720989586458376"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, test_set_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3340790894482488\n"
     ]
    }
   ],
   "source": [
    "p = test_set_pred\n",
    "err = abs(p-y_test)\n",
    "total_err = np.dot(err,err)\n",
    "lasso_rmse = np.sqrt(total_err/len(p))\n",
    "print(lasso_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge w 10 features + scaler transform   R^2 .523   RMSE 1.324"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=array([1.00000e-02, 1.04737e-02, ..., 9.54772e+01, 1.00000e+02]),\n",
       "    cv=5, fit_intercept=True, gcv_mode=None, normalize=False, scoring=None,\n",
       "    store_cv_values=False)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphavec = 10**np.linspace(-2,2,200)\n",
    "\n",
    "Ridge_model = RidgeCV(alphas=alphavec, cv=5)\n",
    "Ridge_model.fit(X_tr, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.470131581250264"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ridge_model.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_pred = lasso.predict(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4720989586458376"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, test_set_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3340790894482488\n"
     ]
    }
   ],
   "source": [
    "p = test_set_pred\n",
    "err = abs(p-y_test)\n",
    "total_err = np.dot(err,err)\n",
    "ridge_rmse = np.sqrt(total_err/len(p))\n",
    "print(ridge_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
